{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UxTStUJ_bdGS"
   },
   "source": [
    "# Solving differential equations (ODEs) for multiple initial conditions.\n",
    "\n",
    "\n",
    "Ordinary differential equations (ODEs) find applications in various fields, including epidemiology, physics, chemistry, banking, and more. Oftentimes, an ODE system requires integration for multiple initial conditions while keeping parameters constant. Additionally, typical datasets often contain missing values, exhibit different durations, and have irregularly spaced data points. This tutorial expands upon the previous Predator-Prey Model tutorial to address these challenges. We will:\n",
    "    \n",
    "\n",
    "1.   Define ODEs and the probabilistic model.\n",
    "2.   Generate synthetic datasets with imperfections.\n",
    "3.   Perform parameter estimation using the MCMC algorithm.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MSj59HlgEjFX",
    "outputId": "cc205c0f-d98a-47a2-b051-e7efd2bd3865"
   },
   "outputs": [],
   "source": [
    "!pip install -q numpyro@git+https://github.com/pyro-ppl/numpyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cnEC2MV1FMlh"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from jax.experimental.ode import odeint\n",
    "import jax.numpy as jnp\n",
    "from jax.random import PRNGKey\n",
    "import jax\n",
    "\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.examples.datasets import LYNXHARE, load_dataset\n",
    "from numpyro.infer import MCMC, NUTS, Predictive\n",
    "import functools\n",
    "from numpyro.infer import (\n",
    "    init_to_median,\n",
    "    init_to_sample,\n",
    "    init_to_mean,\n",
    "    init_to_value,\n",
    "    init_to_uniform,\n",
    "    init_to_feasible,\n",
    ")\n",
    "\n",
    "# Numerical instabilities may arise during ODE solving, so one has sometimes to play around with solver settings, change solver, or change numeric precision as we do here.\n",
    "numpyro.enable_x64(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2ZjUuurtZiw"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdQ6HQL8tdO_"
   },
   "source": [
    "Let's start by defining our differential equations, `dz_dt`, and the probabilistic model, model. The differential equations remain the same as in the Lotka-Volterra tutorial. However, notable changes are introduced in the model to accommodate multiple initial conditions simultaneously. We begin by sampling initial conditions, `z_init`, and parameters, theta. Subsequently, the ODE system is solved in a vectorized form. Vectorization is achieved using `jax.vmap`, with the use of `functools.partial` for passing kwargs. Next, we sample sigma to represent measurement error. Finally, we sample the measured populations. Given that missing values may exist in the observed `y`, we mask non-finite values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B6abPRAHEgOX"
   },
   "outputs": [],
   "source": [
    "def dz_dt(z, t, theta):\n",
    "    \"\"\"\n",
    "    Lotkaâ€“Volterra equations. Real positive parameters `alpha`, `beta`, `gamma`, `delta`\n",
    "    describes the interaction of two species.\n",
    "    \"\"\"\n",
    "    u, v = z\n",
    "    alpha, beta, gamma, delta = theta\n",
    "\n",
    "    du_dt = (alpha - beta * v) * u\n",
    "    dv_dt = (-gamma + delta * u) * v\n",
    "    return jnp.stack([du_dt, dv_dt])\n",
    "\n",
    "\n",
    "def model(ts, y_init, y=None):\n",
    "    \"\"\"\n",
    "    :param numpy.ndarray ts: measurement times\n",
    "    :param numpy.ndarray y_init: measured inital conditions\n",
    "    :param numpy.ndarray y: measured populations\n",
    "    \"\"\"\n",
    "    # initial population\n",
    "    z_init = numpyro.sample(\n",
    "        \"z_init\", dist.LogNormal(jnp.log(y_init), jnp.ones_like(y_init))\n",
    "    )\n",
    "\n",
    "    # parameters alpha, beta, gamma, delta of dz_dt\n",
    "    theta = numpyro.sample(\n",
    "        \"theta\",\n",
    "        dist.TruncatedNormal(\n",
    "            low=0.0,\n",
    "            loc=jnp.array([1.0, 0.05, 1.0, 0.05]),\n",
    "            scale=jnp.array([0.2, 0.01, 0.2, 0.01]),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # helpers to solve ODEs in a vectorized form\n",
    "    odeint_with_kwargs = functools.partial(\n",
    "        odeint, rtol=1e-8, atol=1e-8, mxstep=10000, hmax=1\n",
    "    )\n",
    "    vect_solve_ode = jax.vmap(\n",
    "        odeint_with_kwargs,\n",
    "        in_axes=(None, 0, 0, None),\n",
    "    )\n",
    "\n",
    "    # integrate dz/dt\n",
    "    zs = vect_solve_ode(dz_dt, z_init, ts, theta)\n",
    "    # measurement errors\n",
    "    sigma = numpyro.sample(\"sigma\", dist.LogNormal(-1, 1).expand([2]))\n",
    "    # measured populations\n",
    "    if y is not None:\n",
    "        # mask missing observations in the observed y\n",
    "        mask = jnp.isfinite(jnp.log(y))\n",
    "        numpyro.sample(\"y\", dist.LogNormal(jnp.log(zs), sigma).mask(mask), obs=y)\n",
    "    else:\n",
    "        numpyro.sample(\"y\", dist.LogNormal(jnp.log(zs), sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t22Nb8qrt4j0"
   },
   "source": [
    "# Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ql_vWaIXt8h8"
   },
   "source": [
    "For the purpose of this tutorial, we will utilize synthetic datasets generated by sampling from the previously defined model. To emulate the non-ideal properties of real-life datasets, we will introduce missing values, varying durations, and irregular spacing between timepoints. It's important to note that JAX works with vectorized and compiled calculations, requiring datasets to have the same length. In our case, although we have different spacing, we maintain the same number of points. If it's not the case one can use `jnp.pad` to extend all datasets to the same length with dummy fill values, which can later be masked.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59504Lj8EI2W"
   },
   "source": [
    "First, let's establish simulation settings. The datasets will exhibit varying timespans between `t_min` and `t_max`, with the number of points constrained between `n_points_min` and `n_points_max`. Additionally, we will introduce missing values with a probability of `p_missing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lM6Gw2dKERqU"
   },
   "outputs": [],
   "source": [
    "n_datasets = 5  # int n_datasets: number of datasets to generate\n",
    "t_min = 100  # int t_min: minimal allowed length of the generated time array\n",
    "t_max = 200  # int t_min: maximal allowed length of the generated time array\n",
    "n_points_min = 80  # int n_points_min: minimal allowed number of points in a data set\n",
    "n_points_max = 120  # int n_points_max: maximal allowed number of points in a data set\n",
    "y0_min = 2.0  # float y0_min: minimal allowed value for initial conditions\n",
    "y0_max = 10.0  # float y0_max: maximal allowed value for initial conditions\n",
    "p_missing = 0.1  # float p_missing: probability of having missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jfdW1MqnFJqa"
   },
   "source": [
    "Generate an array with initial conditons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uqkzxKjkFIZZ",
    "outputId": "933017ef-c32c-4685-9c84-78b9b260ba6d"
   },
   "outputs": [],
   "source": [
    "# generate an array with initial conditons\n",
    "z_inits = jnp.array(\n",
    "    [jnp.linspace(y0_min, y0_max, n_datasets), jnp.linspace(y0_max, y0_min, n_datasets)]\n",
    ").T\n",
    "\n",
    "print(f\"Initial conditons are: \\n {z_inits}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQkUy4yRF0MY"
   },
   "source": [
    "Next, let's create a time matrix `ts` to store the time points for each individual dataset. We will generate random integers in `rand_duration` between `t_min` and `t_max` to represent varying durations. Similarly, `rand_n_points` will correspond to different spacings in each dataset. Since JAX requires a matrix with a constant shape, we will use `jnp.pad` to pad individual observations to the common length of the longest array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RhQLsJLaFyK2",
    "outputId": "ab2f41e5-0abc-42c3-d1a4-895962ef59f4"
   },
   "outputs": [],
   "source": [
    "# generate array with random integers between t_min and t_max, representing tiem duration in the data set\n",
    "rand_duration = jax.random.randint(\n",
    "    PRNGKey(1), shape=(n_datasets,), minval=t_min, maxval=t_max\n",
    ")\n",
    "\n",
    "# generate array with random integers between n_points_min and n_points_max, representing number of time points per dataset\n",
    "rand_n_points = jax.random.randint(\n",
    "    PRNGKey(1), shape=(n_datasets,), minval=n_points_min, maxval=n_points_max\n",
    ")\n",
    "\n",
    "# Note that arrays have different length and are stored in a list\n",
    "time_arrays = [\n",
    "    jnp.linspace(0, j, num=rand_n_points[i]).astype(float)\n",
    "    for i, j in enumerate(rand_duration)\n",
    "]\n",
    "longest = jnp.max(jnp.array([len(i) for i in time_arrays]))\n",
    "\n",
    "# Make a time matrix\n",
    "ts = jnp.array(\n",
    "    [\n",
    "        jnp.pad(arr, pad_width=(0, longest - len(arr)), constant_values=jnp.nan)\n",
    "        for arr in time_arrays\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"The shape of the time matrix is {ts.shape}\")\n",
    "print(f\"First values are \\n {ts[:, :10]}\")\n",
    "print(f\"Last values are \\n {ts[:, -10:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6kkkpyiGhwY"
   },
   "source": [
    "We'll utilize the `Predictive` mode from NumPyro to draw a single sample, representing our synthetic dataset. Subsequently, we'll apply a mask with NaNs to the data to simulate missing values. For simplicity, we'll ensure that initial values are non-missing. In real datasets where this may not hold true, then various imputation methods can be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u4aAm3CiGiKD"
   },
   "outputs": [],
   "source": [
    "# take a single sample that will be our synthetic data\n",
    "sample = Predictive(model, num_samples=1)(PRNGKey(100), ts, z_inits)\n",
    "data = sample[\"y\"][0]\n",
    "\n",
    "# create a mask that will add missing values to the data\n",
    "missing_obs_mask = jax.random.choice(\n",
    "    PRNGKey(1),\n",
    "    jnp.array([True, False]),\n",
    "    shape=data.shape,\n",
    "    p=jnp.array([p_missing, 1 - p_missing]),\n",
    ")\n",
    "# make sure that initial values are not missing\n",
    "missing_obs_mask = missing_obs_mask.at[:, 0, :].set(False)\n",
    "\n",
    "# data with missing values\n",
    "data = data.at[missing_obs_mask].set(jnp.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1E57U8xqHzXR"
   },
   "source": [
    "Finally, for compatibility with `NUTS` later on, we need to fill NaN values in the time matrix ts with dummy variables. The `odeint` function from JAX requires these values to be in increasing order. We fill them with values greater than `t_max` from the time matrix. Importantly, these values do not affect the MCMC estimation, as the corresponding values in the `data` are missing and thereby ignored during the posterior estimation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zGpcCr4VHz0D"
   },
   "outputs": [],
   "source": [
    "# fill_nans\n",
    "def fill_nans(ts):\n",
    "    n_nan = jnp.sum(jnp.isnan(ts))\n",
    "    if n_nan > 0:\n",
    "        loc_first_nan = jnp.where(jnp.isnan(ts))[0][0]\n",
    "        ts_filled_nans = ts.at[loc_first_nan:].set(\n",
    "            jnp.linspace(t_max, t_max + 20, n_nan)\n",
    "        )\n",
    "        return ts_filled_nans\n",
    "    else:\n",
    "        return ts\n",
    "\n",
    "\n",
    "ts_filled_nans = jnp.array([fill_nans(t) for t in ts])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdgNlwpHffNI"
   },
   "source": [
    "Let's briefly summarize our synthetic dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ayL4TA6m8cop",
    "outputId": "a1d83349-bc31-4a48-d76a-eb41cf7308fa"
   },
   "outputs": [],
   "source": [
    "print(f\"The dataset has the shape {data.shape}, (n_datasets, n_points, n_observables)\")\n",
    "print(f\"The time matrix has the shape {ts.shape}, (n_datasets, n_timepoints)\")\n",
    "print(f\"The time matrix has different spacing between timepoints: \\n {ts[:,:5]}\")\n",
    "print(f\"The final timepoints are: {jnp.nanmax(ts,1)} years.\")\n",
    "print(\n",
    "    f\"The dataset has {jnp.sum(jnp.isnan(data))/jnp.size(data):.0%} missing observations\"\n",
    ")\n",
    "print(f\"True params mean: {sample['theta'][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4RBZ1BAf7Wd"
   },
   "source": [
    "Let's visualize the dataset, with solid lines helping to guide the eye. You'll notice line breaks where NaN values occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "id": "JhSxTEUcuvXN",
    "outputId": "b66e0ecb-1085-47a5-b1ab-1739c73ef419"
   },
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig, axs = plt.subplots(2, n_datasets, figsize=(15, 4))\n",
    "\n",
    "for i in range(n_datasets):\n",
    "    loc = jnp.where(jnp.isfinite(data[i, :, 0]))[0][-1]\n",
    "\n",
    "    axs[0, i].plot(\n",
    "        ts[i, :], data[i, :, 0], \"ko\", mfc=\"none\", ms=4, label=\"true hare\", alpha=0.67\n",
    "    )\n",
    "    axs[0, i].plot(ts[i, :], data[i, :, 0], label=\"true hare\", alpha=0.67)\n",
    "    axs[0, i].set_xlabel(\"Time, year\")\n",
    "    axs[0, i].set_ylabel(\"Population\")\n",
    "    axs[0, i].set_xlim([-5, jnp.nanmax(ts)])\n",
    "\n",
    "    axs[1, i].plot(ts[i, :], data[i, :, 1], \"bx\", label=\"true lynx\")\n",
    "    axs[1, i].plot(ts[i, :], data[i, :, 1], label=\"true lynx\")\n",
    "    axs[1, i].set_xlabel(\"Time, year\")\n",
    "    axs[1, i].set_ylabel(\"Population\")\n",
    "    axs[1, i].set_xlim([-5, jnp.nanmax(ts)])\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8DSzUkX7vxCU"
   },
   "source": [
    "# Perform MCMC.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hH9g3l7n3TiK",
    "outputId": "a5bea3eb-3948-410c-8df3-9ea40a6b5b46"
   },
   "outputs": [],
   "source": [
    "y_init = data[:, 0, :]\n",
    "\n",
    "mcmc = MCMC(\n",
    "    NUTS(\n",
    "        model,\n",
    "        dense_mass=True,\n",
    "        init_strategy=init_to_sample(),\n",
    "        max_tree_depth=4,\n",
    "    ),\n",
    "    num_warmup=1000,\n",
    "    num_samples=1000,\n",
    "    num_chains=1,\n",
    "    progress_bar=False if \"NUMPYRO_SPHINXBUILD\" in os.environ else True,\n",
    ")\n",
    "\n",
    "mcmc.run(PRNGKey(1031410), ts=ts_filled_nans, y_init=y_init, y=data)\n",
    "mcmc.print_summary()\n",
    "\n",
    "print(f\"True params mean: {sample['theta'][0]}\")\n",
    "print(f\"Estimated params mean: {jnp.mean(mcmc.get_samples()['theta'], axis = 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UyujXNDJD3vQ"
   },
   "source": [
    "# Run predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0yeZoVcnYEX",
    "outputId": "96cb818a-36b9-4314-e8b3-a0294bbf8406"
   },
   "outputs": [],
   "source": [
    "# predict\n",
    "ts_pred = jnp.tile(jnp.linspace(0, 200, 1000), (n_datasets, 1))\n",
    "pop_pred = Predictive(model, mcmc.get_samples())(PRNGKey(1041140), ts_pred, y_init)[\"y\"]\n",
    "mu = jnp.mean(pop_pred, 0)\n",
    "pi = jnp.percentile(pop_pred, jnp.array([10, 90]), 0)\n",
    "\n",
    "\n",
    "print(f\"True params mean: {sample['theta'][0]}\")\n",
    "print(f\"Estimated params mean: {jnp.mean(mcmc.get_samples()['theta'], axis = 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "radhqpROiajF"
   },
   "source": [
    "Plot the observed points and predicted mean with prediction intervals.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "id": "306Em01uXfhA",
    "outputId": "037c48da-9a58-475c-8e65-0add143b3af1"
   },
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig, axs = plt.subplots(2, n_datasets, figsize=(15, 4))\n",
    "\n",
    "for i in range(n_datasets):\n",
    "    loc = jnp.where(jnp.isfinite(data[i, :, 0]))[0][-1]\n",
    "\n",
    "    axs[0, i].plot(\n",
    "        ts_pred[i, :], mu[i, :, 0], \"k-.\", label=\"pred hare\", lw=1, alpha=0.67\n",
    "    )\n",
    "    axs[0, i].plot(\n",
    "        ts[i, :], data[i, :, 0], \"ko\", mfc=\"none\", ms=4, label=\"true hare\", alpha=0.67\n",
    "    )\n",
    "    axs[0, i].fill_between(\n",
    "        ts_pred[i, :], pi[0, i, :, 0], pi[1, i, :, 0], color=\"k\", alpha=0.2\n",
    "    )\n",
    "    axs[0, i].set_xlabel(\"Time, year\")\n",
    "    axs[0, i].set_ylabel(\"Population\")\n",
    "    axs[0, i].set_xlim([-5, jnp.nanmax(ts)])\n",
    "\n",
    "    axs[1, i].plot(ts_pred[i, :], mu[i, :, 1], \"b--\", label=\"pred lynx\")\n",
    "    axs[1, i].plot(ts[i, :], data[i, :, 1], \"bx\", label=\"true lynx\")\n",
    "    axs[1, i].fill_between(\n",
    "        ts_pred[i, :], pi[0, i, :, 1], pi[1, i, :, 1], color=\"b\", alpha=0.2\n",
    "    )\n",
    "    axs[1, i].set_xlabel(\"Time, year\")\n",
    "    axs[1, i].set_ylabel(\"Population\")\n",
    "    axs[1, i].set_xlim([-5, jnp.nanmax(ts)])\n",
    "\n",
    "\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPQk9jay6ceAtuxJER0gMKR",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
